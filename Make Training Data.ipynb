{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from GANsynth_pytorch.pytorch_nsynth_lib.nsynth import (\n",
    "    NSynth, WavToSpectrogramDataLoader)\n",
    "\n",
    "from GANsynth_pytorch import phase_operation\n",
    "from GANsynth_pytorch.utils import plots\n",
    "from GANsynth_pytorch import spec_ops\n",
    "from GANsynth_pytorch import phase_operation as phase_op\n",
    "from GANsynth_pytorch import spectrograms_helper as spec_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'valid'\n",
    "\n",
    "base_path = Path('~/code/data/nsynth/').expanduser()\n",
    "subsets = ['train', 'valid']\n",
    "\n",
    "audio_directory_paths = [base_path / subset / 'json_wav/audio/'\n",
    "                         for subset in subsets]\n",
    "\n",
    "json_data_paths = {subset: base_path / subset / 'json_wav/examples.json'\n",
    "                   for subset in subsets}\n",
    "\n",
    "balanced_splits_base_path = Path(\n",
    "    '/home/theis/code/data/nsynth-balanced-split-fixed_seed/').expanduser()\n",
    "balanced_splits_json_data_paths = {\n",
    "    subset: balanced_splits_base_path / subset / 'examples.json'\n",
    "    for subset in subsets}\n",
    "\n",
    "# use instrument_family and pitch as classification targets\n",
    "dataset = NSynth(audio_directory_paths=audio_directory_paths,\n",
    "                 json_data_path=json_data_paths[subset],\n",
    "                 categorical_field_list=[\"instrument_family\",\"pitch\"],\n",
    "                 valid_pitch_range=[24, 84]\n",
    "                )\n",
    "FS_HZ = dataset[0][3]['sample_rate']  # assumes constant sampling rate accross the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOP_LENGTH = 512\n",
    "\n",
    "use_mel_scale = True\n",
    "mel_break_frequency_hertz = 700\n",
    "\n",
    "loader = WavToSpectrogramDataLoader(dataset, batch_size=1, shuffle=False,\n",
    "                                    device='cuda',\n",
    "                                    use_mel_scale=use_mel_scale,\n",
    "                                    mel_break_frequency_hertz=mel_break_frequency_hertz,\n",
    "                                    fs_hz=FS_HZ, hop_length=HOP_LENGTH)\n",
    "shuffled_loader = WavToSpectrogramDataLoader(\n",
    "    dataset, batch_size=1, shuffle=True,\n",
    "    device='cuda',\n",
    "    use_mel_scale=use_mel_scale,\n",
    "    mel_break_frequency_hertz=mel_break_frequency_hertz,\n",
    "    fs_hz=FS_HZ, hop_length=HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(mat):\n",
    "    \"\"\"\"Repeat the last column of the input matrix twice\"\"\"\n",
    "    expand_vec = np.expand_dims(mat[:,125],axis=1)\n",
    "    expanded = np.hstack((mat,expand_vec,expand_vec))\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the computed representations\n",
    "\n",
    "Re-run the cell to visualize representations on a different input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_loader_iterator = iter(shuffled_loader)\n",
    "samples, *_, targets = next(shuffled_loader_iterator)\n",
    "sample_name = targets['note_str'][0]\n",
    "\n",
    "pitch = targets['pitch'].data.numpy()[0]\n",
    "\n",
    "sample = samples.data.cpu().numpy().squeeze()\n",
    "plots.plot_mel_representations(sample[0], sample[1],\n",
    "                              hop_length=HOP_LENGTH, fs_hz=FS_HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "window_length = 1023\n",
    "\n",
    "window_scipy = scipy.signal.windows.hann(window_length)\n",
    "window_torch = torch.hann_window(window_length)\n",
    "\n",
    "print(torch.nn.functional.mse_loss(torch.from_numpy(window_scipy),\n",
    "                                   window_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "target_n_fft = 2048\n",
    "mel_downscale = 1\n",
    "n_fft = target_n_fft * mel_downscale\n",
    "window_length = target_n_fft // 2\n",
    "hop_length = window_length // 4\n",
    "\n",
    "sample_index = np.random.randint(0, len(dataset))\n",
    "sample_index = 7871\n",
    "# sample_index = 5875\n",
    "print(sample_index)\n",
    "sample = dataset[sample_index]\n",
    "sample_name = sample[3]['note_str']\n",
    "print(\"sample_name\", sample_name)\n",
    "audio = sample[0].flatten()\n",
    "\n",
    "# original audio\n",
    "IPython.display.display(IPython.display.Audio(audio.cpu(), rate=FS_HZ))\n",
    "librosa.display.waveplot(audio.numpy(), sr=FS_HZ)\n",
    "plt.show()\n",
    "    \n",
    "for my_mel_break_frequency in [80, 120, 180, 200, 700, 2000]:\n",
    "# for my_mel_break_frequency in [80]:\n",
    "    my_loader = WavToSpectrogramDataLoader([], batch_size=1, shuffle=False,\n",
    "                                           device='cuda',\n",
    "                                           use_mel_scale=True,\n",
    "                                           lower_edge_hertz=20.,\n",
    "                                           upper_edge_hertz=8000.,\n",
    "                                           mel_break_frequency_hertz=my_mel_break_frequency,\n",
    "                                           n_fft=n_fft,\n",
    "                                           hop_length=hop_length,\n",
    "                                           window_length=window_length,\n",
    "                                           mel_downscale=mel_downscale,\n",
    "                                           fs_hz=FS_HZ,\n",
    "                                           expand_resolution_factor=1.1)\n",
    "    \n",
    "    spectrogram = my_loader.to_spectrogram(audio.unsqueeze(0)\n",
    "                                          ) # samples[0].data.cpu().numpy()\n",
    "    spectrogram_np = spectrogram.squeeze(0).cpu().numpy()\n",
    "    reconstructed_audio = my_loader.to_audio(spectrogram).cpu()\n",
    "    \n",
    "    print(spectrogram.shape)\n",
    "    plots.plot_mel_representations(spectrogram_np[0], spectrogram_np[1],\n",
    "                                   hop_length=hop_length, fs_hz=FS_HZ)\n",
    "    plt.show()\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(reconstructed_audio[0], rate=FS_HZ))\n",
    "    librosa.display.waveplot(reconstructed_audio[0].numpy(), sr=FS_HZ)\n",
    "    plt.show()\n",
    "    print(torch.nn.functional.mse_loss(audio/audio.abs().max(),\n",
    "                                       (reconstructed_audio[0][:audio.size(0)].cpu()\n",
    "                                        /reconstructed_audio[0][:audio.size(0)].abs().max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_stored_sample = random.choice(list(save_path.glob('*.h5')))\n",
    "with h5py.File(random_stored_sample, 'r') as sample_file:\n",
    "    IF = sample_file['IF']\n",
    "    logmelmag2 = sample_file['mel_Spec']\n",
    "    mel_p = sample_file['mel_IF']\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    librosa.display.specshow(logmelmag2, sr=FS_HZ, hop_length=HOP_LENGTH,\n",
    "                            y_axis='mel')\n",
    "    plt.title(\"log-melspectrogram\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    librosa.display.specshow(IF, sr=FS_HZ, hop_length=HOP_LENGTH,\n",
    "                             y_axis='linear')\n",
    "    plt.title(\"IF\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    librosa.display.specshow(mel_p, sr=FS_HZ, hop_length=HOP_LENGTH,\n",
    "                             y_axis='mel')\n",
    "    plt.title(\"mel-IF\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_EXISTING = False\n",
    "count = 0\n",
    "\n",
    "for samples, pitch, targets in tqdm(loader):\n",
    "    sample_name = targets['note_str'][0]\n",
    "    h5_file_path = h5_save_path / f'{sample_name}.h5'\n",
    "    \n",
    "    if SKIP_EXISTING and h5_file_path.is_file(): \n",
    "        # skip already created file\n",
    "        continue\n",
    "\n",
    "    pitch = targets['pitch'].data.numpy()[0]\n",
    "\n",
    "    if pitch < 24 or pitch > 84:\n",
    "        # filter-out extreme pitches, as advocated by GANSynth\n",
    "        continue\n",
    "    \n",
    "    sample = samples.data.numpy().squeeze()\n",
    "    spec = librosa.stft(sample, n_fft=2048, hop_length = 512)\n",
    "    \n",
    "    magnitude = np.log(np.abs(spec) + 1.0e-6)[:1024]\n",
    "    angle =np.angle(spec)\n",
    "\n",
    "    IF = phase_operation.instantaneous_frequency(angle, time_axis=1)[:1024]\n",
    "    \n",
    "    magnitude = expand(magnitude)\n",
    "    IF = expand(IF)\n",
    "    logmelmag2, mel_p = spec_helper.specgrams_to_melspecgrams(magnitude, IF)\n",
    "    \n",
    "    assert magnitude.shape == (1024, 128)\n",
    "    assert IF.shape == (1024, 128)\n",
    "    with h5py.File(h5_file_path, 'w') as sample_file:\n",
    "        sample_file.create_dataset(\"Spec\", data=magnitude.astype(np.float32))\n",
    "        sample_file.create_dataset(\"IF\", data=IF.astype(np.float32))\n",
    "        sample_file.create_dataset(\"mel_Spec\", data=logmelmag2.astype(np.float32))\n",
    "        sample_file.create_dataset(\"mel_IF\", data=mel_p.astype(np.float32))\n",
    "        sample_file.attrs.create(\"pitch\", data=pitch)\n",
    "    \n",
    "    if count % 500 == 0:\n",
    "        clear_output(wait=True)\n",
    "        plot_representations(magnitude, angle[:1024], IF, logmelmag2, mel_p)\n",
    "        IPython.display.display(IPython.display.Audio(sample, rate=16000))\n",
    "    count +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
